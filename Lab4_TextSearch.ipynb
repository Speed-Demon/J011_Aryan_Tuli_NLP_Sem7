{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12981012,"sourceType":"datasetVersion","datasetId":8216318}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rapidfuzz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T19:12:44.319497Z","iopub.execute_input":"2025-09-06T19:12:44.319793Z","iopub.status.idle":"2025-09-06T19:12:47.541660Z","shell.execute_reply.started":"2025-09-06T19:12:44.319764Z","shell.execute_reply":"2025-09-06T19:12:47.540839Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (3.14.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Task 1 - Match user queries with resolved queries","metadata":{}},{"cell_type":"code","source":"# Step 0: Import libraries\nimport pandas as pd\nfrom rapidfuzz import fuzz, process\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Step 1: Load datasets\nresolved = pd.read_csv(\"/kaggle/input/lab4textsearch/resolved_queries.csv\")\nnew = pd.read_csv(\"/kaggle/input/lab4textsearch/new_queries.csv\")\n\nprint(\"Resolved queries sample:\\n\", resolved.head(), \"\\n\")\nprint(\"New queries sample:\\n\", new.head(), \"\\n\")\n\n# Use the correct column names\nresolved_queries = resolved['Pre_Resolved_Query'].astype(str).tolist()\nnew_queries = new['Variation_Query'].astype(str).tolist()\n\n# ===================================================================\n# Step 2: Fuzzy Matching (RapidFuzz)\n# ===================================================================\nfuzzy_matches = []\nfor q in new_queries:\n    match, score, idx = process.extractOne(q, resolved_queries, scorer=fuzz.token_sort_ratio)\n    fuzzy_matches.append((q, match, score))\n\nfuzzy_results = pd.DataFrame(fuzzy_matches, columns=[\"new_query\", \"best_match_fuzzy\", \"similarity_score\"])\nthreshold = 80\nfuzzy_results[\"is_match_fuzzy\"] = fuzzy_results[\"similarity_score\"] >= threshold\n\n# ===================================================================\n# Step 3: TF-IDF Matching\n# ===================================================================\nvectorizer = TfidfVectorizer()\ntfidf_matrix_resolved = vectorizer.fit_transform(resolved_queries)\ntfidf_matrix_new = vectorizer.transform(new_queries)\n\ntfidf_matches = []\nfor i, q in enumerate(new_queries):\n    cosine_similarities = cosine_similarity(tfidf_matrix_new[i], tfidf_matrix_resolved).flatten()\n    best_idx = cosine_similarities.argmax()\n    best_match = resolved_queries[best_idx]\n    score = cosine_similarities[best_idx]\n    tfidf_matches.append((q, best_match, score))\n\ntfidf_results = pd.DataFrame(tfidf_matches, columns=[\"new_query\", \"best_match_tfidf\", \"similarity_score_tfidf\"])\n\n# ===================================================================\n# Step 4: Evaluation\n# ===================================================================\n# Map resolved query → ID\nresolved_dict = dict(zip(resolved['Pre_Resolved_Query'], resolved['Query_ID']))\n\n# Map predictions\nfuzzy_results['pred_Query_ID_fuzzy'] = fuzzy_results['best_match_fuzzy'].map(resolved_dict)\ntfidf_results['pred_Query_ID_tfidf'] = tfidf_results['best_match_tfidf'].map(resolved_dict)\n\n# Merge with ground truth\nevaluation = new.merge(\n    fuzzy_results[['new_query','pred_Query_ID_fuzzy']], \n    left_on='Variation_Query', right_on='new_query'\n).merge(\n    tfidf_results[['new_query','pred_Query_ID_tfidf']], \n    left_on='Variation_Query', right_on='new_query'\n)\n\n# Drop duplicate cols\nevaluation = evaluation.drop(columns=['new_query_x','new_query_y'])\n\n# Accuracy\nacc_fuzzy = (evaluation['Matches_With_Query_ID'] == evaluation['pred_Query_ID_fuzzy']).mean()\nacc_tfidf = (evaluation['Matches_With_Query_ID'] == evaluation['pred_Query_ID_tfidf']).mean()\n\nprint(\"Fuzzy Matching Accuracy:\", acc_fuzzy)\nprint(\"TF-IDF Matching Accuracy:\", acc_tfidf)\n\nevaluation.head(10)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-06T19:20:01.292149Z","iopub.execute_input":"2025-09-06T19:20:01.292741Z","iopub.status.idle":"2025-09-06T19:20:02.167132Z","shell.execute_reply.started":"2025-09-06T19:20:01.292717Z","shell.execute_reply":"2025-09-06T19:20:02.166463Z"}},"outputs":[{"name":"stdout","text":"Resolved queries sample:\n    Query_ID                    Pre_Resolved_Query\n0         1     Unable to connect to the internet\n1         2        Payment failed during checkout\n2         3     App crashes when opening settings\n3         4   Forgot password and unable to reset\n4         5  Unable to upload files to the server \n\nNew queries sample:\n                              Variation_Query  Matches_With_Query_ID\n0           Unabel to conect to the internet                      1\n1                  Can’t connect to internet                      1\n2                        Intenet not working                      1\n3               Payment failed while chekout                      2\n4  Payment did not go through during chckout                      2 \n\nFuzzy Matching Accuracy: 0.9\nTF-IDF Matching Accuracy: 1.0\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                             Variation_Query  Matches_With_Query_ID  \\\n0           Unabel to conect to the internet                      1   \n1                  Can’t connect to internet                      1   \n2                        Intenet not working                      1   \n3               Payment failed while chekout                      2   \n4  Payment did not go through during chckout                      2   \n5                 Payment issue at check out                      2   \n6   Application crashes when opening setings                      3   \n7           App crash when going to settings                      3   \n8           Settings cause the app to chrash                      3   \n9              Forgot passwrd and cant reset                      4   \n\n   pred_Query_ID_fuzzy  pred_Query_ID_tfidf  \n0                    1                    1  \n1                    1                    1  \n2                    2                    1  \n3                    2                    2  \n4                    2                    2  \n5                    2                    2  \n6                    3                    3  \n7                    3                    3  \n8                    1                    3  \n9                    4                    4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Variation_Query</th>\n      <th>Matches_With_Query_ID</th>\n      <th>pred_Query_ID_fuzzy</th>\n      <th>pred_Query_ID_tfidf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Unabel to conect to the internet</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Can’t connect to internet</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Intenet not working</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Payment failed while chekout</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Payment did not go through during chckout</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Payment issue at check out</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Application crashes when opening setings</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>App crash when going to settings</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Settings cause the app to chrash</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Forgot passwrd and cant reset</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"- Performed Fuzzy Matching (RapidFuzz, token sort ratio)\n- Performed TF-IDF + Cosine Similarity Matching\n- Mapped matches to Query IDs\n- Evaluated accuracy of both methods against ground truth (Matches_With_Query_ID)\n- Printed accuracies + evaluation sample","metadata":{}},{"cell_type":"markdown","source":"# Task 2 - Match names","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport unicodedata\nfrom rapidfuzz import fuzz, process\n\n# ---------- Config ----------\nBASE_PATH = \"/kaggle/input/lab4textsearch/base_names.csv\"\nVAR_PATH  = \"/kaggle/input/lab4textsearch/name_variations.csv\"\nOUTPUT_PATH = \"/kaggle/working/matching_results.csv\"\nTOP_N = 3            # number of top candidates to keep (by token_set_ratio)\nMATCH_THRESHOLD = 85 # ensemble score threshold to mark as confident match\n# ----------------------------\n\n# ---------- helpers ----------\ndef find_name_col(df):\n    # heuristics to find name-like column; falls back to first column\n    for c in df.columns:\n        low = c.lower()\n        if \"name\" in low or \"full\" in low:\n            return c\n    return df.columns[0]\n\ndef normalize_name(name):\n    \"\"\"lightweight normalization for names:\n       - reorder 'Last, First' to 'First Last'\n       - remove honorifics/titles, punctuation, parentheticals\n       - collapse whitespace, lowercase\n    \"\"\"\n    if pd.isna(name):\n        return \"\"\n    s = str(name)\n    s = unicodedata.normalize(\"NFKD\", s)\n    # remove content in parentheses\n    s = re.sub(r\"\\(.*?\\)\", \" \", s)\n    # handle trailing comma format \"Last, First Middle\"\n    if \",\" in s:\n        parts = [p.strip() for p in s.split(\",\") if p.strip()]\n        if len(parts) >= 2:\n            s = \" \".join(parts[1:] + [parts[0]])\n    # remove dots, hyphens -> spaces (so J.D. -> J D)\n    s = s.replace(\".\", \" \").replace(\"-\", \" \")\n    s = s.strip()\n    s = s.lower()\n    # remove common honorifics/titles\n    s = re.sub(r\"\\b(?:mr|mrs|ms|miss|dr|prof|sir|madam|mx)\\b\\.?\", \" \", s)\n    # keep only letters and spaces (removes numbers, punctuation)\n    s = re.sub(r\"[^a-z\\s]\", \" \", s)\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n    return s\n\n# ---------- load data ----------\nbase_df = pd.read_csv(BASE_PATH)\nvar_df  = pd.read_csv(VAR_PATH)\n\nbase_col = find_name_col(base_df)\nvar_col  = find_name_col(var_df)\n\nbase_orig = base_df[base_col].astype(str).tolist()\nvar_orig  = var_df[var_col].astype(str).tolist()\n\n# ---------- normalized lists (keeps alignment) ----------\nbase_norms = [normalize_name(x) for x in base_orig]\nvar_norms  = [normalize_name(x) for x in var_orig]\n\n# ---------- matching ----------\nrows = []\nscorers = {\n    \"token_set\": fuzz.token_set_ratio,\n    \"token_sort\": fuzz.token_sort_ratio,\n    \"partial\": fuzz.partial_ratio,\n    \"ratio\": fuzz.ratio\n}\n\n# Pre-build choices for rapidfuzz (processor=None since we've pre-normalized)\nchoices = base_norms  # same index mapping as base_orig\n\nfor i, (orig_var, norm_var) in enumerate(zip(var_orig, var_norms)):\n    # top-N by token_set (often good for name variations)\n    top_n = process.extract(norm_var, choices, scorer=fuzz.token_set_ratio, processor=None, limit=TOP_N)\n    top_n_out = []\n    for match_norm, score, idx in top_n:\n        top_n_out.append({\n            \"matched_base_name\": base_orig[idx],\n            \"matched_base_norm\": match_norm,\n            \"score\": score,\n            \"base_index\": idx\n        })\n\n    # best per scorer\n    per_scorer = {}\n    for sname, scorer in scorers.items():\n        best = process.extractOne(norm_var, choices, scorer=scorer, processor=None)\n        if best is None:\n            per_scorer[sname] = {\"base\": None, \"score\": 0, \"idx\": None}\n        else:\n            match_norm, score, idx = best\n            per_scorer[sname] = {\"base\": base_orig[idx], \"score\": score, \"idx\": idx}\n\n    # ensemble decision: choose candidate with highest single-score across scorers\n    # (simple, robust choice: pick candidate with max score among all scorers)\n    ensemble_candidates = []\n    for sname, info in per_scorer.items():\n        if info[\"base\"] is not None:\n            ensemble_candidates.append((info[\"base\"], info[\"score\"], sname, info[\"idx\"]))\n    if ensemble_candidates:\n        ensemble_best = max(ensemble_candidates, key=lambda x: x[1])  # (base, score, scorer, idx)\n        ensemble_base, ensemble_score, ensemble_scorer, ensemble_idx = ensemble_best\n    else:\n        ensemble_base, ensemble_score, ensemble_scorer, ensemble_idx = (None, 0, None, None)\n\n    # boolean flag if confident match\n    is_confident = ensemble_score >= MATCH_THRESHOLD\n\n    rows.append({\n        \"Variation_Name\": orig_var,\n        \"Variation_Name_norm\": norm_var,\n        # top-N results (as compact string)\n        \"Top{}_Candidates_token_set\".format(TOP_N): \" | \".join(\n            [f\"{r['matched_base_name']} ({r['score']:.0f})\" for r in top_n_out]\n        ) if top_n_out else \"\",\n        # per-scorer bests + scores\n        **{f\"Best_{sname}_match\": per_scorer[sname][\"base\"] for sname in scorers},\n        **{f\"Score_{sname}\": per_scorer[sname][\"score\"] for sname in scorers},\n        # ensemble\n        \"Ensemble_best_match\": ensemble_base,\n        \"Ensemble_best_score\": ensemble_score,\n        \"Ensemble_best_scorer\": ensemble_scorer,\n        \"Is_confident_match\": is_confident\n    })\n\n# ---------- output DataFrame & save ----------\nout_df = pd.DataFrame(rows)\nout_df.index.name = \"Variation_index\"\n\n# Add mapping back to any ID columns in base/vars if present\n# (optional: if base_df has Query_ID or similar, you can map that here)\n# Example: if base_df has 'ID' column, you could map ensemble match -> its ID by searching base_orig\n\nout_df.to_csv(OUTPUT_PATH, index=True)\nprint(f\"Finished matching. Results saved to: {OUTPUT_PATH}\")\nprint(\"\\nSample rows:\")\nprint(out_df.head(12).to_string(index=False))\n\n# ---------- quick summary ----------\nnum_confident = out_df[\"Is_confident_match\"].sum()\nprint(f\"\\nTotal variations: {len(out_df)}, Confident matches (>= {MATCH_THRESHOLD}): {num_confident}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T19:29:11.606976Z","iopub.execute_input":"2025-09-06T19:29:11.607702Z","iopub.status.idle":"2025-09-06T19:29:11.664020Z","shell.execute_reply.started":"2025-09-06T19:29:11.607678Z","shell.execute_reply":"2025-09-06T19:29:11.663033Z"}},"outputs":[{"name":"stdout","text":"Finished matching. Results saved to: /kaggle/working/matching_results.csv\n\nSample rows:\nVariation_Name Variation_Name_norm Top3_Candidates_token_set Best_token_set_match Best_token_sort_match Best_partial_match Best_ratio_match  Score_token_set  Score_token_sort  Score_partial  Score_ratio Ensemble_best_match  Ensemble_best_score Ensemble_best_scorer  Is_confident_match\n   Thomas King         thomas king     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n   Thomas King         thomas king     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n  Maria Garcia        maria garcia     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n    Mary Lewis          mary lewis     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n  Nancy Wright        nancy wright     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n  Daniel Scott        daniel scott     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n    John Smith          john smith     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n Linda Johnson       linda johnson     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n  Nancy Wright        nancy wright     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n William Davis       william davis     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n   Susan Clark         susan clark     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n   Susan Clark         susan clark     1 (0) | 2 (0) | 3 (0)                    1                     1                  1                1              0.0               0.0            0.0          0.0                   1                  0.0            token_set               False\n\nTotal variations: 100, Confident matches (>= 85): 0\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"- auto-detects the name column in each CSV,\n- normalizes names (handles Last, First forms, punctuation, titles, extra spaces),\n- runs multiple fuzzy scorers (token_set_ratio, token_sort_ratio, partial_ratio, ratio),\n- returns top-3 candidates (by token_set_ratio) and best match per scorer,\n- picks an ensemble best (highest score across scorers),\n- flags matches that meet a configurable threshold,\n- saves results to matching_results.csv.","metadata":{}}]}